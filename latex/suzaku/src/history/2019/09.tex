\section{09}

\subsection{02}

开始recovery模块的开发。通过一两天搞定编码。逐步迭代。
scan阶段要做到不重不漏。

如何回收chunk？不重不漏的原则，redo要安全。

先mark，再删除redis，再回收bitmap。需要同步alloc和delete两种操作。
在存在mark的情况下，对应的磁盘空间不能被reuse。

统一后台任务处理框架已基本搭建好。\hl{明天可完成删除卷的工作}。

测试方面：磁盘漫游。nvme需要先切换回kernel态，需要先还给kernel？

用ramdisk测试dm8，性能如何？

采用oracle作横向对比？能得出什么结论？存储-DB-测试工具三个层面，瓶颈何在？

最重要的是什么？

\subsection{03}

\subsection{04}

mellanox的1012支持ib、以太模式切换，6012不支持。现在发现1012也不支持，license问题？

\hl{如何从ib切换到以太}，交换机和网卡，配置HOWTO手册。

明日用rc2分支发版，测试手册里要说明已知条件和问题，同时指明如何配置。

\subsection{05}

\subsection{06}

\subsection{07}

新来的盘，导致没通过hazard一致性测试。如何验证盘本身的可靠性？还是driver和disk之间的兼容问题。

\subsection{08}

\subsection{09}

长城测试进展：
\begin{myeasylist}{itemize}
& 硬件：
&& 一个交换机能切换到RoCE
&& 飞腾上安装CentOS 7.5?
& suzaku rc2：周五hazard测试发现不一致现象，经反复定位，换回原来的nvme盘，可以稳定运行
& Oracle性能对比测试？
\end{myeasylist}

估算内存使用量的方法

\hrulefill

平衡：多趟scan，第一趟得到卷的所有chunk的副本在disk上的分布情况。
第二趟依次从最满的disk往最空的disk上迁移副本，直到各disk的used或利用率的差值小于等于预定值。

一个chunk可以移动的条件：
\begin{myeasylist}{itemize}
& 该副本位于大于disk平均利用率的disk上
& 满足故障域规则
\end{myeasylist}

需要考虑range的平衡性吗？交叉选取chunk？

这样，即可以满足卷上数据的平衡性，又可以满足disk利用率的平衡性。

\subsection{11}

平衡和恢复机制
\begin{myeasylist}{itemize}
& job manager
& range\_chunk\_move
& cds\_gc
\end{myeasylist}

gc支持sync和async两种模式。

如何在各节点之间分配任务？
\begin{myeasylist}{itemize}
& 获取pool内nodelist
& 按nid升序排列，依次获取编号0、1等
& 获取pool内所有卷列表
& \hl{每个节点选取属于自己的那部分数据}进行处理
\end{myeasylist}

if 节点列表发生变化

if 磁盘列表发生变化

if pool发生变化

if 卷列表发生变化

少数大卷的情况，如何尽量均衡负载？

平衡和恢复有何不同？

\subsection{12}

分工并明确责任到人，做好\hl{制度设计}。

分工是相对的划分，不是一成不变的，有主次之分。

开展团队学习活动。

好书
\begin{myeasylist}{itemize}
& \hl{计算机体系结构精髓}
& 并行多核体系结构基础
\end{myeasylist}

coremask的HOWTO，哪些配置是不合法的？

两个网卡配了同一ip地址

\subsection{16}

whitepaper和性能之巅的培训ppt。

\subsection{17}

存储一致性，缓存一致性。

在bus体系结构下，目录式缓存一致性协议比广播式更具伸缩性。

\hrulefill

质量

P = f(R)，C是物理资源、f是体系结构，\hl{P是输出，代表客户价值}。f是R -> P的映射。
体系结构的重要性在此。算法、架构、设计的实用性和趣味性在此。

\hl{响应式宣言突出了系统的质量属性}，这也是架构设计的主要考虑方向。
质量考量渗透到每项功能之中。

CAP定理及其v2，关注的也主要是质量属性。

怎么理解阵列、分布式存储的控制器概念？

控制器/target是导出服务的组件，一个LUN可以通过任一controller导出/挂载。

卷控、子卷控制器是内部实现细节。

CPU指令集架构：存储系统也可抽象成指令集，指令集的设计遵循正交原则。

\hl{精读论文、书籍、产品文档}，提炼关键问题，持续思考其解决方案。

场景，考虑系统的使用场景，不同场景的要求和特点是什么？

\hrulefill

紫光云测试：
\begin{myeasylist}{itemize}
& 网卡不能做bridge，极大降低性能。
& 能加入同一disk多次？
& 通过disk、network估算最高性能。先评估network的latency和带宽。
& SATA SSD只能采用aio方式，aio thread的配比怎么优化？
& RoCE需要交换机配置QoS
\end{myeasylist}

\subsection{18}

默认coremask不工作，会产生coredump, why?

如果异常，要有补偿措施，拨乱反正，回归到稳态。观察正态分布、正弦曲线。

开启snapshot？

mdctl提供的是kv接口(raw slice)，内部则采用pa接口。key是chkid，v是chkinfo。
volume slice、range slice由mdctl内部管理，上层应用查询和更新的是raw slice的元数据。

memblaze实现的是nvme v1.3，libnvme实现的是v1.2，有没有兼容性问题？
每个关键组件都要进行全面评估。

git: 已push到remote，如何回到到某个commit
\begin{myeasylist}{itemize}
& git reset
& git push --force origin rc2:rc2
& git revert
\end{myeasylist}

target实现为何改的面目全非，而不是用plugin的方式？

当前的几个重要任务：
\begin{myeasylist}{itemize}
& GFM
& Recovery and balance
& Restful API
& snapshot
& others
&& nvme driver (采用最新spdk？)
&& 把spdk/dpdk纳入深度学习计划
\end{myeasylist}

\hrulefill

\hl{spdk本质上是一个单机软件}，提供了端到端的组件：target、driver、以及对应linux kernel的块存储层次。

spdk没有副本、分布式等，主要是如何单进程环境的主要任务。

单卷是靠单核提供服务的，每个core是同样的，不像suzaku一样为了完成一个io，可以调动多核资源。

先看其driver。driver是对NVMe协议标准的实现，非常基础。driver之上，bdev、blobfs等，增强易用性。

\hl{提取-保存范式}适用于任何io设备。

看其thread抽象，thread采用polling模式，采用QPair方式。可以lockless。
内存也是分核预留的，binding thread到cpu core，因为局部性，cache的效用显著。

这是event-driven的进一步演化。\hl{epoll wait支持两种模式：硬件中断和PMD}，但因为要陷入kernel，不是最好做法。
进一步的做法就是DMA，kernel bypass。不再由kernel维护QPair，而是在用户空间维护。\hl{设备可以读写主机内存缓冲区}。

访问一个nvme设备有两种方式：一、kernel driver；二、spdk driver。spdk driver通过pci号进行访问。
通过专用io指令、或\hl{mmio进行存取}。往一块内存区域写数据，就相当于向设备控制器发送了指令。
指令遵循NVMe规范。注意：这里出现了controller。controller广泛出现在盘阵、OS等技术领域。
设备控制器对内存区域包含的指令进行解码、执行。所以、设备控制器可以看作是另外一个处理器。
\hl{io过程看作主机处理器与设备处理器直接协作的过程}。两者通过bus进行通信。跑满总线带宽是最理想的结果。

访问线程与pci设备的映射关系是多对多。多个线程访问同一NVMe disk，不会降低性能？

\begin{myeasylist}{itemize}
& user space (kernel bypass)
& zero copy
& polling mode
& async
& lockless
& highly parallel
\end{myeasylist}

所谓polling，主要指完成队列。

bus和switch结构的同异。

suzaku block应封装在bdev后面，作为一bdev实现而对接到spdk？

应分层来看suzaku block。target - libsuzaku/suzaku，突出target与suzaku的边界。
\hl{suzaku藏于bdev之后？nvmf等target可拿来直接用？}

\subsection{19}

发挥优势，优势是什么？健康、优势、专注、关系、目标。

\hrulefill

ringlock，主要用途即在于检测ring是否发生了变化。

在partition里维护ring map信息，同步更新。每个rangectl持有的本地信息，
与最新信息的版本不一致时，发生ESTALE。此时尝试刷新本地信息，直至成功。

两个版本比较

\hl{从数据模型开始}，怎么分片、怎么复制。怎么表达树状结构？怎么保证复制之间的一致性。

自然地划分range。

卷的元数据，引入中间层，增加扩展性。再切换到flat view，转化为KV DB。

\hrulefill

target是软件定义的虚拟实体，可以通过tgtctl导出。

login是login target，login成功后，该target下的所有lun都可见，可以连接。discovery和connect不同。

client group，允许哪些client访问一个target，需要另一层mapping。

\hl{client - target - lun(volume)}，构成两层映射关系。

现在的实现，target-lun是一对一映射，即一个lun构成一个target，此为默认行为，不需单独定义。
一个lun只能属于一个target，target与lun之间是一对多的映射关系。

会话和连接信息集中存放到mds上。mds充当etcd的agent角色。

huayun实现target直接attach到core，suzaku则突出了tgtctl as controller的角色。
tgtctl是initiator与存储服务的交互界面。

\hrulefill

多点写

target级别维护epoch，叫target epoch。NOP是initiator与target之间的心跳(1s)，心跳超时(5s)后会连接其他target。

每个活动连接维护ttl

该信息可以得到\hl{一个卷的所有活动连接}，可用于删除卷时的前置条件检查。

\subsection{20}

好好理解message-driven的意思，在不同的上下文去理解。SEDA、reactive programming、stream等都是message based。

响应式架构，reactor反应堆。这是reactive提出的主要方法。

\hrulefill

cmd与ioctl进程看到的coremask不同，\hl{cmd的coremask=1。同时daemon=0}。ioctl的core array是稀疏的。指向实际的物理core。
根据这些条件，初始化了不同的结构。其中的一项是task sche。

外部线程要执行corerpc，必须借道core。core未必绑定到cpu。最小依赖是什么？

同样的corehash，未必指向物理core。

\hl{sche与别的poller是什么关系，如何协作}？

\subsection{25}

write接口在rlock打开的情况下，经过了4k的RMW对齐。read则没有对齐操作，io会下发下去。

spdk的write、writev接口有区别？libnvme也是用的write接口。
\hl{spdk的write接口对nvme v1.3不兼容}？见于memblaze。

libnvme上次遇到的问题也是没有处理好virt addr和phy addr的对应关系。
一定要同步变动。

\hrulefill

工具

./identify可以查看NVMe disk的协议版本。

nvme的lba format设为4096，因为有512的read io，出现cpl is error的现象。

\hrulefill

有什么方法可以提升suzaku的iSER性能？以什么接口呈现？封装在bdev之后，就可以直接用spdk的各种target了吧。

host端如何配置，怎么才能做到全用户态，包括host端。

\hl{spdk内部会按128k拆分大io}，xfer size。

\hrulefill

TODO

kernel soft lockup，no hugepage，发生\hl{在集群重启的时候，没有卸载iSER连接}。
此时一直尝试连接，为什么会导致以上现象呢？

插入新盘导致io error，ioctl重启时，无法分配内存。

dd if=/dev/sdd of=/dev/null bs=5k count=1 seek=3584 iflag=direct

读只需要512对齐即可，direct重要，否则看到不同大小的io。

dd if=/dev/zero of=/dev/sdd bs=5k count=1 seek=3584 oflag=direct

\hl{写并非必须4k对齐, 甚至不要求512对齐？}。

spdk对io的规则是什么？
\begin{myeasylist}{itemize}
& off
& size
& buffer
& 多个iov，每个iov的规则？
\end{myeasylist}

\hl{拥抱spdk，逐渐弃用libnvme}，虽然简单，但已无更新，spdk本身提供的更多，可以择优利用。

\subsection{26}

spdk很好玩，深入进去。

scaling 一块nvme disk通过多队列来支持多线程访问，每个线程通过一个qpair操作disk。这是core上的扩展性。

hazard的测试方法：hazard运行在vm centos 6x里，挂载host的盘。
host是centos 7x系列，作为iSCSI initiator，挂载suzaku的卷。

hazard用c2，只跑disk raw。排除xfs和ext4的干扰。

\hrulefill

工具

hwloc下的lstopo，检查NUMA下资源分布情况，特别是内存。

\hl{ntpdate 5.79.108.34} 同步时钟

\hl{hwclock --systohc} 同步系统时间到硬件，防止重启后丢失。

timedatectl查看时间

改写spdk的setup.sh脚本，由suzaku设置nr\_hugepages等变量。

新旧盘的区别，新盘会触发soft lockup。

IRQ disabled的，以及dmesg出出现的消息，两种盘看上去是一致的。

\subsection{27}

spdk分上中下三层，实现端到端的io路径。

dpdk完成底层环境的抽象。

ci已能跑通，原因是什么？

\subsection{29}


