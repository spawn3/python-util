\chapter{系统架构}

\section{硬件架构}

\subsection{通用服务器}

系统运行在通用服务器之上，多台服务器组成分布式存储系统，按硬件配置提供相应的服务。

\subsection{磁盘}

支持SATA SSD、NVMe SSD。

\subsection{网络}

推荐RDMA网络，包括IB、支持RoCE v2的以太网等。

\section{软件架构}

% \mygraphics{../imgs/arch/system-arch.png}

\mygraphics{../imgs/suzaku/suzaku-function.png}

\subsection{块级虚拟化}

提供标准的iSCSI、iSER、NVMf target，可用于各种场景下的块存储服务。

\subsection{分布式架构}

分布式架构具有良好的可扩展性，可以方便地进行垂直或水平扩展。

\subsection{元数据服务}

\mygraphics{../imgs/vol-metadata.png}

系统内置元数据服务，每个卷的元数据均匀分布在后端磁盘上，支持的最大单卷容量可达4PB。

卷进一步化分为子卷，子卷控制器分布在不同的节点上，从而实现卷性能和容量的scale out。

不同于基于分布式哈希表的存储系统，在内置元数据的协助下，可以受控地进行数据恢复、平衡等后台任务，
使系统表现更稳定，以最小化对前端业务的影响

同时，一个存储池下卷的数量不受限，可以灵活地根据业务需求创建卷。

\subsection{负载均衡}

系统的均衡性体现在许多层面，如数据均衡、负载均衡。

数据均衡有两个过程保证：首次分配过程和再平衡过程。

卷可以通过任一tgt控制器导出，卷进一步划分为子卷，每个子卷负责管理该卷的一部分数据，
子卷通过hash过程均匀分布在不同存储节点的多个子卷控制器上。
这样，数据和负载都能平衡地分布在存储池内的所有节点和磁盘上。

% \subsection{控制路径和数据路径分离}

% \subsection{丰富的存储特性}

\subsection{面向全闪的系统优化}

SSD盘的优势在于随机IO性能好，时延低，劣势在于需要进行磨损均衡，以提升其平均使用寿命。
系统采取了适当措施，充分利用相关硬件特性，以实现更好的可靠性和性能。

在全闪场景下，需要重新考虑传统IO路径的效率问题，操作系统服务、锁争用、硬中断和IO编程模型等都严重制约了SSD的性能。

通过合理地使用cpu核、自定义内存分配器、高效的编程模型等技术能充分地发挥全闪的性能优势。

系统的不同服务映射到专属线程上，这些线程绑定到独立的cpu核上，有定制的内存分配器负责内存管理，
可以避免访问共享内存的锁定机制，极大地提高了性能。

\subsection{全用户态}

采用kernel bypass技术，达到极致性能。可通过用户态驱动访问NVMe SSD，通过RDMA技术释放网络性能，从而使高吞吐、低延时系统成为可能。

\subsection{极致性能}

\mygraphics{../imgs/io-path.png}

一个卷的IO可以调用多个核进行处理。

首先，卷可以通过任一tgt控制器导出，tgt控制器把相关请求分发到多个前端控制器上执行(frctl)。
然后，每个frctl进一步下发请求到子卷控制器和后端控制器，从而实现了专核专用的并行流水线架构。
