\chapter{软件架构}

meta管理采用对称的中心化架构。在节点中选举出admin节点，
管理全局状态和数据分配工作。当admin节点发生故障时，会发生
failover过程，选举出新的admin节点来。

lichd进程内嵌各种server，包括iscsi等。

作为存储系统，主要考虑是元数据组织和IO，恢复等关键过程。
功能之外，性能，可靠性，可扩展性至关重要。

client可以和每个节点进行通信，推荐采用VIP机制，简化连接管理。

\section{节点}

三类服务器节点：
\begin{compactenum}
\item admin
\item meta
\item normal
\end{compactenum}

从meta节点中选举出admin。meta节点是静态指定的吗？meta节点列表构成一个小的集群，类似于ceph的monitor。

normal节点是数据节点，存放元数据和数据。元数据和数据都是按1M的chunk组织。
元数据包括四类chunk: pool，subpool，vol，subvol。每个chunk具有固定数目的槽位bucket，指向管理的下一级节点。
集群内的所有chunk，构成一个单根树。每个pool，每个volume，都是这个大树下的子树。

引导信息bootstrap：rootable。记录了根分区的位置，即所在chunk的位置信息。根分区是一个特殊的pool。

所有的控制器，包括pool和volume控制器，通过lease机制保证集群内的唯一性。
其节点位置，由所在子树的根chunk的主副本确定。

chunk副本的节点分布：基于diskmap的随机分布算法，并记录在元数据里。

chunk副本的磁盘分布：本地数据管理（bitmap+sqlite）

chunk副本之间的一致性：强一致性协议。

\subsection{admin节点}

职责：
\begin{compactenum}
\item paxos leader
\item lease server
\item 管理系统引导信息
\item 集群节点列表
\item 维护diskmap
\item VIP（控制器当前位置）
\item 分配卷Id
\item 分配\hl{chunk副本位置}
\end{compactenum}

持久化信息和上报信息，心跳机制

可扩展性

\section{VIP}

\section{分布}

数据分布首先要满足规则要求，其次则需做到均衡和局部性。
规则是强制的，极端条件下可能退化。均衡和局部性则影响系统性能。

数据分布规则有：
\begin{compactitem}
\item 保护域规则
\item 存储池规则
\item 故障域规则(\ref{rule:faultset})
\end{compactitem}

负载均衡和本地化两方面考虑，平衡包括数据平衡和任务平衡。

chunk在节点上的分布，节点内chunk在磁盘上的分布（包括分层）

controller在节点上的分布，controller在core上的分布

进一步，需要考虑保护域，存储池，故障域各自的作用和特性。

\section{复制}

\begin{tabular}{|s|p{6cm}|}
    %\hline
    %\rowcolor{lightgray} \multicolumn{5}{|c|} {Snapshot} \\
    \hline
    pool & LICH\_REPLICA\_METADATA  \\
    \hline
    subpool & LICH\_REPLICA\_METADATA  \\
    \hline
    vol & fileinfo \\
    \hline
    subvol & fileinfo  \\
    \hline
    raw & fileinfo  \\
    \hline
\end{tabular}

恢复和再平衡过程，是怎么工作的？

\section{分配和回收}

\subsection{分配一个chunk的过程}

函数：
\begin{compactitem}
\item \verb|__table2_chunk_create|
\item \verb|replica_srv_create|
\item \verb|disk_create|
\end{compactitem}

与admin交互，返回节点列表，即各副本所在节点。

需要持久化的信息：
\begin{compactitem}
\item table2 meta，记录chunk info（副本位置）
\item sqlite3，记录chkid（副本）到物理地址的映射关系
\item disk bitmap，记录磁盘上每个chunk的分配状态
\item 填充chunk内容为全0？
\end{compactitem}

分配chunk的过程，会影响到若干特性，如精简配置，恢复，再平衡，写入等，都产生新chunk。

优化allocate的性能：
\begin{compactitem}
\item 异步化sqlite，每个db一个工作线程
\item 加大lich.inspect线程数到20
\item table2 lock粒度 \change{dynamical lock table}
\end{compactitem}

\subsection{磁盘管理}

每块磁盘对应一个bitmap，用于该盘的空间管理。

磁盘有分层属性，通常0表示SSD，1表示HDD。有三种分层策略：tier==0，表示写入SSD，tier==1表示写入HDD，
tier==-1表示自动分层，先写入SSD，通过异步后台线程flush不活跃的数据到HDD。

在分配每一个chunk的时候，可以指定tier。没有指定的情况下，默认为卷的priority设定。

chunk\_id到磁盘物理地址的映射，是一随机过程，定位到空闲的bitmap上。

如何确定磁盘的分层？

RAID管理，disk和raid都有cache，需要注意掉电情况下是否丢数据。

\section{IO过程}

写过程，可能内在地包含了分配chunk的过程，缺页分配。当在末尾写入时，还可能扩展了卷的大小。

大范围内的随机写入，造成很多的缺页分配，分配过程会成为性能瓶颈。

\section{负载均衡}

\section{本地化}

卷控制器所在节点，具有所有chunk的副本。

当切换控制器的时候，需要控制本地化过程的QoS。

\section{分层}

\section{SSD缓存}
